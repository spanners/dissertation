# Further work

In addition to fixing these flaws/foibles, an improvement over this experimental
method is to take people who are new -- as in: never having used Elm or JS, and
train them up either in JS or Elm, and then run the same task.  That way, their
level of ability is much more comparable. 

My current method creates quite a bit of noise in the data, because I rely on
self-reported level of expertise in JS/Functional languages. I don't know how to
modify the data to account for this. I could group the analyses into categories
-- i.e those who reported being experts at JS, those who reported never having
used it, those who reported being experts in at least one FP language, and those
who reported being new, and make cross comparisons with groups of equal levels
of ability.

Furthermore, can I be sure that the operationalisation of thrash (the concept) I
have chosen, i.e. cementing the concept by a metric to model cognitive load, is
a positive indicator?
